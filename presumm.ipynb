{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitfastabs65cc00d0c4884a83a3d7e226faf00aaf",
   "display_name": "Python 3.8.5 64-bit ('fastabs')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from train_full_rl import load_ext_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading checkpoint ckpt-2.486399-18000...\n"
     ]
    }
   ],
   "source": [
    "extractor, agent_vocab = load_ext_net(\"./cnn/extm_cnn/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.rl import ActorCritic\n",
    "from decoding import Abstractor, ArticleBatcher\n",
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "agent = ActorCritic(extractor._sent_enc,\n",
    "                        extractor._art_enc,\n",
    "                        extractor._extractor,\n",
    "                        ArticleBatcher(agent_vocab, cuda))\n",
    "if cuda:\n",
    "    agent = agent.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# source1 = json.load(open(\"/exp/yashgupta/cnndm/finished_files/train/20.json\", \"r\"))[\"article\"] \n",
    "# tgt1 = json.load(open(\"/exp/yashgupta/cnndm/finished_files/train/20.json\", \"r\"))[\"abstract\"] \n",
    "# print(len(source1))\n",
    "# print(len(tgt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source1.to(cuda)\n",
    "# agent(source1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data import CnnDmDataset\n",
    "DATA_DIR = \"/exp/yashgupta/cnndm/finished_files/\"\n",
    "class RLDataset(CnnDmDataset):\n",
    "    \"\"\" get the article sentences only (for decoding use)\"\"\"\n",
    "    def __init__(self, split):\n",
    "        super().__init__(split, DATA_DIR)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        js_data = super().__getitem__(i)\n",
    "        art_sents = js_data['article']\n",
    "        abs_sents = js_data['abstract']\n",
    "        return art_sents, abs_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# loader = DataLoader(\n",
    "#         RLDataset('train'), batch_size=1,\n",
    "#         shuffle=True, num_workers=4,\n",
    "#         collate_fn=coll\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train_full_rl import build_batchers\n",
    "from itertools import cycle\n",
    "from toolz.sandbox.core import unzip\n",
    "from data.batcher import tokenize\n",
    "def build_batchers(batch_size):\n",
    "    def coll(batch):\n",
    "        art_batch, abs_batch = unzip(batch)\n",
    "        art_sents = list(filter(bool, map(tokenize(None), art_batch)))\n",
    "        abs_sents = list(filter(bool, map(tokenize(None), abs_batch)))\n",
    "        return art_sents, abs_sents\n",
    "    loader = DataLoader(\n",
    "        RLDataset('train'), batch_size=batch_size,\n",
    "        shuffle=True, num_workers=4,\n",
    "        collate_fn=coll\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        RLDataset('val'), batch_size=batch_size,\n",
    "        shuffle=False, num_workers=4,\n",
    "        collate_fn=coll\n",
    "    )\n",
    "    return cycle(loader), val_loader\n",
    "# DATA_DIR = \"/exp/yashgupta/cnndm/finished_files/\"\n",
    "train_batcher, val_batcher = build_batchers(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_batch, abs_batch = next(train_batcher)\n",
    "for raw_arts in art_batch:\n",
    "    # print(raw_arts)\n",
    "    (inds, ms), bs = agent(raw_arts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(17, 17, 17)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "len(inds), len(ms), len(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Categorical(probs: torch.Size([1, 17]))"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "ms[0]\n",
    "# len(abs_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor([[0.3297]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.1225]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.1051]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0866]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0585]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0525]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0497]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0487]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0480]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0475]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0471]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0467]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0462]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0458]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0454]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0452]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0450]], device='cuda:0', grad_fn=<AddmmBackward>)]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../PreSumm/src/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'myextract' from '/exp/yashgupta/PreSumm/src/myextract.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "import myextract, importlib\n",
    "importlib.reload(myextract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../PreSumm/src/')))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from os.path import join\n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "\n",
    "from cytoolz import identity\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data.batcher import tokenize\n",
    "\n",
    "from decoding import Abstractor, Extractor#, DecodeDataset\n",
    "from decoding import make_html_safe\n",
    "MAX_ABS_NUM = 6  # need to set max sentences to extract for non-RL extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data import CnnDmDataset\n",
    "DATASET_DIR = \"/exp/yashgupta/cnndm2/finished_files/\" #CHANGE BACK\n",
    "class DecodeDataset(CnnDmDataset):\n",
    "    \"\"\" get the article sentences only (for decoding use)\"\"\"\n",
    "    def __init__(self, split):\n",
    "        assert split in ['val', 'test']\n",
    "        super().__init__(split, DATASET_DIR)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        js_data = super().__getitem__(i)\n",
    "        art_sents = js_data['article']\n",
    "        abs_sents = js_data['abstract']\n",
    "        return art_sents, abs_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading checkpoint ckpt-3.053677-87000...\n"
     ]
    }
   ],
   "source": [
    "abstractor = Abstractor(\"./cnn2/absm_cnn/\", 50, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"test\"\n",
    "import os\n",
    "os.environ['DATA'] = \"/exp/yashgupta/cnndm2/finished_files/\"\n",
    "DATASET_DIR = os.environ[\"DATA\"]\n",
    "def coll(batch):\n",
    "        articles = list(filter(bool, batch))\n",
    "        return articles\n",
    "dataset = DecodeDataset(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = len(dataset)\n",
    "loader = DataLoader(\n",
    "    dataset, batch_size=4, shuffle=False, num_workers=4,\n",
    "    collate_fn=coll\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11490"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'myextract' from '/exp/yashgupta/PreSumm/src/myextract.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "import myextract, importlib\n",
    "importlib.reload(myextract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i_debug, raw_article_batch in enumerate(loader):\n",
    "        tokenized_article_batch = map(tokenize(None), raw_article_batch)\n",
    "        ext_arts = []\n",
    "        ext_inds = []\n",
    "        for raw_art_sents in tokenized_article_batch:\n",
    "            ext = myextract.extractor(raw_art_sents)\n",
    "            ext_inds += [(len(ext_arts), len(ext))]\n",
    "            ext_arts += list(map(lambda i: raw_art_sents[i], ext))\n",
    "        dec_outs = abstractor(ext_arts)\n",
    "        assert i == batch_size*i_debug\n",
    "        for j, n in ext_inds:\n",
    "            decoded_sents = [' '.join(dec) for dec in dec_outs[j:j+n]]\n",
    "            for k, dec_str in enumerate(decoded_sents):\n",
    "                with open(join(save_path, 'output_{}/{}.dec'.format(k, i)),\n",
    "                            'w') as f:\n",
    "                    f.write(make_html_safe(dec_str))\n",
    "\n",
    "            i += 1\n",
    "            print('{}/{} ({:.2f}%) decoded in {} seconds\\r'.format(\n",
    "                i, n_data, i/n_data*100, timedelta(seconds=int(time()-start))\n",
    "            ), end='')\n",
    "    print()"
   ]
  }
 ]
}