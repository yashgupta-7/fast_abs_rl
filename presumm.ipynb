{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitfastabs65cc00d0c4884a83a3d7e226faf00aaf",
   "display_name": "Python 3.8.5 64-bit ('fastabs')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: METEOR is not configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from train_full_rl import load_ext_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading checkpoint ckpt-2.486399-18000...\n"
     ]
    }
   ],
   "source": [
    "extractor, agent_vocab = load_ext_net(\"./cnn/extm_cnn/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.rl import ActorCritic\n",
    "from decoding import Abstractor, ArticleBatcher\n",
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "agent = ActorCritic(extractor._sent_enc,\n",
    "                        extractor._art_enc,\n",
    "                        extractor._extractor,\n",
    "                        ArticleBatcher(agent_vocab, cuda))\n",
    "if cuda:\n",
    "    agent = agent.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# source1 = json.load(open(\"/exp/yashgupta/cnndm/finished_files/train/20.json\", \"r\"))[\"article\"] \n",
    "# tgt1 = json.load(open(\"/exp/yashgupta/cnndm/finished_files/train/20.json\", \"r\"))[\"abstract\"] \n",
    "# print(len(source1))\n",
    "# print(len(tgt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source1.to(cuda)\n",
    "# agent(source1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data import CnnDmDataset\n",
    "DATA_DIR = \"/exp/yashgupta/cnndm/finished_files/\"\n",
    "class RLDataset(CnnDmDataset):\n",
    "    \"\"\" get the article sentences only (for decoding use)\"\"\"\n",
    "    def __init__(self, split):\n",
    "        super().__init__(split, DATA_DIR)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        js_data = super().__getitem__(i)\n",
    "        art_sents = js_data['article']\n",
    "        abs_sents = js_data['abstract']\n",
    "        return art_sents, abs_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# loader = DataLoader(\n",
    "#         RLDataset('train'), batch_size=1,\n",
    "#         shuffle=True, num_workers=4,\n",
    "#         collate_fn=coll\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train_full_rl import build_batchers\n",
    "from itertools import cycle\n",
    "from toolz.sandbox.core import unzip\n",
    "from data.batcher import tokenize\n",
    "def build_batchers(batch_size):\n",
    "    def coll(batch):\n",
    "        art_batch, abs_batch = unzip(batch)\n",
    "        art_sents = list(filter(bool, map(tokenize(None), art_batch)))\n",
    "        abs_sents = list(filter(bool, map(tokenize(None), abs_batch)))\n",
    "        return art_sents, abs_sents\n",
    "    loader = DataLoader(\n",
    "        RLDataset('train'), batch_size=batch_size,\n",
    "        shuffle=True, num_workers=4,\n",
    "        collate_fn=coll\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        RLDataset('val'), batch_size=batch_size,\n",
    "        shuffle=False, num_workers=4,\n",
    "        collate_fn=coll\n",
    "    )\n",
    "    return cycle(loader), val_loader\n",
    "# DATA_DIR = \"/exp/yashgupta/cnndm/finished_files/\"\n",
    "train_batcher, val_batcher = build_batchers(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_batch, abs_batch = next(train_batcher)\n",
    "for raw_arts in art_batch:\n",
    "    # print(raw_arts)\n",
    "    (inds, ms), bs = agent(raw_arts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor([[-0.0758]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2107]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2464]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2656]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2692]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2716]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2721]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2720]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2715]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2708]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2698]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2689]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2682]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2677]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2674]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2672]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2671]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2670]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.2670]], device='cuda:0', grad_fn=<AddmmBackward>)]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(19, 19, 19)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "len(inds), len(ms), len(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Categorical(probs: torch.Size([1, 17]))"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "ms[0]\n",
    "# len(abs_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor([[0.3297]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.1225]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.1051]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0866]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0585]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0525]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0497]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0487]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0480]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0475]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0471]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0467]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0462]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0458]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0454]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0452]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[0.0450]], device='cuda:0', grad_fn=<AddmmBackward>)]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../PreSumm/src/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'myextract' from '/exp/yashgupta/PreSumm/src/myextract.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "import myextract, importlib\n",
    "importlib.reload(myextract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../PreSumm/src/')))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from os.path import join\n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "\n",
    "from cytoolz import identity\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data.batcher import tokenize\n",
    "\n",
    "from decoding import Abstractor, Extractor#, DecodeDataset\n",
    "from decoding import make_html_safe\n",
    "MAX_ABS_NUM = 6  # need to set max sentences to extract for non-RL extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data import CnnDmDataset\n",
    "DATASET_DIR = \"/exp/yashgupta/cnndm2/finished_files/\" #CHANGE BACK\n",
    "class DecodeDataset(CnnDmDataset):\n",
    "    \"\"\" get the article sentences only (for decoding use)\"\"\"\n",
    "    def __init__(self, split):\n",
    "        assert split in ['val', 'test']\n",
    "        super().__init__(split, DATASET_DIR)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        js_data = super().__getitem__(i)\n",
    "        art_sents = js_data['article']\n",
    "        abs_sents = js_data['abstract']\n",
    "        return art_sents, abs_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading checkpoint ckpt-3.053677-87000...\n"
     ]
    }
   ],
   "source": [
    "abstractor = Abstractor(\"./cnn2/absm_cnn/\", 50, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"test\"\n",
    "import os\n",
    "os.environ['DATA'] = \"/exp/yashgupta/cnndm2/finished_files/\"\n",
    "DATASET_DIR = os.environ[\"DATA\"]\n",
    "def coll(batch):\n",
    "        articles = list(filter(bool, batch))\n",
    "        return articles\n",
    "dataset = DecodeDataset(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = len(dataset)\n",
    "loader = DataLoader(\n",
    "    dataset, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=coll\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11490"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'myextract' from '/exp/yashgupta/PreSumm/src/myextract.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "import myextract, importlib\n",
    "importlib.reload(myextract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dbc31be1ce55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mext_inds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext_arts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mext_arts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mext\u001b[0m \u001b[0;31m#list(map(lambda i: raw_art_sents[i], ext))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdec_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabstractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext_arts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi_debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/exp/yashgupta/fast_abs_rl/decoding.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, raw_article_sents)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mdec_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_article_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mdecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdec_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/exp/yashgupta/fast_abs_rl/model/copy_summ.py\u001b[0m in \u001b[0;36mbatch_decode\u001b[0;34m(self, article, art_lens, extend_art, extend_vsize, go, eos, unk, max_len)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dec_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             tok, states, attn_score = self._decoder.decode_step(\n\u001b[0m\u001b[1;32m     72\u001b[0m                 tok, states, attention)\n\u001b[1;32m     73\u001b[0m             \u001b[0mattns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/exp/yashgupta/fast_abs_rl/model/summ.py\u001b[0m in \u001b[0;36mdecode_step\u001b[0;34m(self, tok, states, attention)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/exp/yashgupta/fast_abs_rl/model/copy_summ.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, tok, states, attention)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mgen_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_gen_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextend_vsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# compute the probabilty of each copying\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mcopy_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;31m# add the copy prob to existing vocab distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         lp = torch.log(\n",
      "\u001b[0;32m~/exp/fastabs/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/exp/yashgupta/fast_abs_rl/model/copy_summ.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, context, state, input_)\u001b[0m\n\u001b[1;32m     30\u001b[0m         output = (torch.matmul(context, self._v_c.unsqueeze(1))\n\u001b[1;32m     31\u001b[0m                   \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                   + torch.matmul(input_, self._v_i.unsqueeze(1)))\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_b\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from tdqm.notebook import tqdm\n",
    "i=0\n",
    "batch_size = 1\n",
    "save_path = \"/exp/yashgupta/fast_abs_rl/cnn2/dec_cnn_presumm_abs\"\n",
    "start = time()\n",
    "with torch.no_grad():\n",
    "    for i_debug, x in enumerate(loader):\n",
    "        # print(x)\n",
    "        [(raw_article_batch, raw_abs_batch)] = x\n",
    "        # print(raw_abs_batch)\n",
    "        # tokenized_article_batch, tokenized_abs_batch = map(tokenize(None), [raw_article_batch]), map(tokenize(None),  [raw_abs_batch])\n",
    "        # print(tokenized_abs_batch)\n",
    "        ext_arts = []\n",
    "        ext_inds = []\n",
    "        for raw_art_sents, raw_abs_sents in zip([raw_article_batch], [raw_abs_batch]):\n",
    "            # print(raw_art_sents, raw_abs_sents)\n",
    "            ext = myextract.extractor([raw_art_sents], [raw_abs_sents])\n",
    "            ext_inds += [(len(ext_arts), len(ext))]\n",
    "            ext_arts += ext #list(map(lambda i: raw_art_sents[i], ext))\n",
    "        dec_outs = abstractor(ext_arts)\n",
    "        assert i == batch_size*i_debug\n",
    "        # print(i)\n",
    "        for j, n in ext_inds:\n",
    "            decoded_sents = [' '.join(dec) for dec in dec_outs[j:j+n]]\n",
    "            for k, dec_str in enumerate(decoded_sents):\n",
    "                with open(join(save_path, 'output/{}.dec'.format(i)),\n",
    "                            'w') as f:\n",
    "                    f.write(make_html_safe(dec_str))\n",
    "\n",
    "            i += 1\n",
    "            if (i%100==0):\n",
    "                print(i)\n",
    "            print('{}/{} ({:.2f}%) decoded in {} seconds\\r'.format(\n",
    "                i, n_data, i/n_data*100, timedelta(seconds=int(time()-start))\n",
    "            ), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}